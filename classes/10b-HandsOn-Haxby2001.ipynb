{
 "metadata": {
  "name": "",
  "signature": "sha256:b485fc5c10f29df2322fc91815733318e7ed8d9c1eb699be8ff17039ce5c0a21"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Hands-on: Numerical Python -- Getting Real -- Let's reproduce Haxby 2001"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Do you remember `tutorial_data` we have fetched and used for some excercises?  It is a single subject from [Haxby et al 2001](http://www.sciencemag.org/content/293/5539/2425.long) paper.  Today we will try to reproduce (at least partially) the analysis and results reported in the paper, in particular:\n",
      "\n",
      "![haxby2001_fig4](http://www.sciencemag.org/content/293/5539/2425/F4.large.jpg)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We will though analyze two different masks, instead of looking at *all* vs *maximal responsive* voxels: eov (early visual cortex) and vt (ventra temporal cortex).\n",
      "\n",
      "All necessary data is available from `tutorial_data` we have fetched earlier using git-annex:  `tutorial_data/data/attributes.txt` provides us labels for each of the TRs and run index."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!head tutorial_data/data/attributes.txt "
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Read the stimulus data file from attributes.txt, and obtain two numpy arrays/vectors:\n",
      "targets = \n",
      "chunks = "
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We will need to load the same BOLD and masks for early visual and ventra-temporal corteces."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Load BOLD data per each ROI into a dictionary containing data arrays per each mask\n",
      "ROIs = ('vt', 'hoc')\n",
      "# all_data = {...}"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "But meanwhile let's start working with a single ROI, e.g. 'vt'"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data = all_data['vt']"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Using `chunks` array we have loaded, first split `data` (and `stimuli`) into even and odd runs"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now per each of the two splits, estimate mean response pattern per each category (among `stimuli`)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Compute correlations between those patterns across splits/targets"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Visualize them using similar to the publication -- no error bars, nor fancy images, but category labels (`targets`) should be there"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Code refactoring\n",
      "\n",
      "Now we have all functionality, given some data and a design, to obtain correlation between different categories across splits of data.  In the next cell, let's create a function which would incorporate the code we have developed above:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def haxby2001_analysis(data, stimuli):\n",
      "    # TODO\n",
      "    return correlations"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "which we could now apply to the data for multiple ROIs we have previously loaded into `all_data`:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "but before jumping to visualize the results, given our respect to testing, what kind of unit-tests could we create?"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from nose.testing import assert_equal\n",
      "from numpy.testing import assert_array_equal\n",
      "\n",
      "def test_haxby2001_TODO():\n",
      "    # TEST IT\n",
      "    pass\n",
      "\n",
      "test_haxby2001_TODO()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "and after we got confidence that things are working as the should, we could generate our fancy ultimate figure demostrating our results with barplots:\n",
      "similarly to the original figure make them of different colors for within/between categories and two different ROIs we have:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import matplotlib.pyplot as plt"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "plt.bar"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Extra for hungry minds\n",
      "\n",
      "Fetch all of the haxby2001 study data, reuse above code/function to process all the subjects and adjust your ultimate plot with mean and stderr bars across subjects:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!git clone http://data.pymvpa.org/datasets/haxby2001/.git"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!cd haxby2001; git annex get */bold.nii.gz */labels.txt */mask*"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}